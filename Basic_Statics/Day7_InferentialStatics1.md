# Inferential Statistics
## Normal and Binomial Distributions

Inference is the science of making decisions over a population analizing the information that gives just a subset of the population, the sample data.

## Introduction

The inference definition from Merriam-Webster online dictionary:
The act of passing from statistical sample data to generalizations (as of the value of population parameters) usually with calculated degrees of certainty.
We already explained descriptive statistics in previous posts, there's no incompatibility between them and inferential statistics, but it's necessary to define the objective of each analysis and choose the right ones. 
* If the objective is just analize the data, go with Descriptive Statistics.
* If the objective is generalize the information of the data and infer to new data, go with Inferential Staticstics

## Probability Distribution

Inference is abouut making assumptions about the way data is distributed, try to fit it in a known distribution applying some type of transformation. That's why we need to introduce some theorical probability distributions with known properties.
If the actual distribution of a given data set is reasonably close to that of a theoretical probability distribution, many calculations can be performed on the actual data by using assumptions drawn from the theoretical distribution.

### Normal Distribution

It's the most common distribution in statics, that's because:
* A lot of continous variables from biological analysis and industrial processes are naturally distributed following Normal Distributions.
* Under specific conditions, we can assume that a sample is normally distributed, even if samples are drawn from populations not normaly distributed.

The normal distribution with mean 0 and standart deviation 1, is known as standart normal distribution and any normal distribution can be standarized.

The characteristics, regardless of the mean and standart distribution are:
* Symmetry.
* Unimodality (The central values is always the unique mode).
* Range continous from negative infinity to positive infinity.
* A total area of 1 under the curve.
* Mean, Median and Mode always have the same value. 

If we read the distribution using standart deviation, we can compare all normal distributions, that's possible because all of them have the same shape.
Empirical rules for any normal distribution are:
* 68% of the data will fall within one standard deviation of the mean.
* 95% of the data will fall within two standard deviations of the mean.
* 99% of the data will fall within three standard deviations of the mean.

![Image of DT](https://github.com/CrunchyPistacho/100DaysOfML/blob/master/Basic_Statics/images/Standard_deviation_diagram.png)
(Image license here: https://creativecommons.org/licenses/by-sa/3.0/deed.en )

Comparisons between single values agains the data are made using Z-scores, which express value of the score in terms of units of the standard deviation. This process is analogous to standarize the distribution. 
Z-scores can be read as distances from the centrer of the distribution expressed in units of standart deviation. The calculation of them is the following:

![Image of DT](https://github.com/CrunchyPistacho/100DaysOfML/blob/master/Basic_Statics/images/Z-score.PNG)

To express a normal distribution we just need the mean and the standart deviation, for example variable x with mean = 100 and sd =  10 is expressed as:

![Image of DT](https://github.com/CrunchyPistacho/100DaysOfML/blob/master/Basic_Statics/images/Normal_expression.PNG)

For tha last example the Z-score of 105 is **(105–100)/10 = 0.5**. Our score is near the mean, in the 68% of the central data, it's a usually expected score.

### Binomial Distribution

Normal distribution is perfect for continous data, but what if we have discrete data it does not work, here comes the Binomial Distribution.
It's generated based on the probability of a set of events happening, for example, the number of faces that we will obtain when throwing a coin 5 times.
Events in a binomial distribution are generated by a Bernoulli process. Binomial distribution describes the number of successes in n trials of a Bernoulli process.
A Bernoully process is a sequence of independent identically distributed binary trials.
To use binomial distribution, data need to meet the following requirements:

* The outcome of each trial is one of two mutually exclusive outcomes. (If the data has more than 2 categories, we can use one hot encode).
* Each trial is independent, so the result of one trial has no influence on the result of any other trial.
* The probability of success, denoted as p, is constant for every trial.
* There is a fixed number of trials, denoted as n.

The probability of getting exactly k successes in n independent Bernoulli trials is given by the probability mass function:

![Image of DT](https://github.com/CrunchyPistacho/100DaysOfML/blob/master/Basic_Statics/images/Binomdist.PNG)

With this formula, we obtain the probability of getting a particular number of successes(k) given a fixed probability(p) of success per trial and a fixed number of trials(n).
For example, the probability to obtain 2 times a, in 4 iterations where probability of A is 0.4 and the probability of B is 0.6 is:

![Image of DT](https://github.com/CrunchyPistacho/100DaysOfML/blob/master/Basic_Statics/images/Binomex.PNG)

The result is 0.345, so, we expect to obtain 2 A is 0.345.

## Summary

This was an introduction to 2 of the most used probability distributions, there exist a lot of them, and for most of models, we will need to use data with specific distributions. 
Statistics can be tough, but if you make sure to understand the basics, you will be able to apply all advanced machine learning models faster and understand the process and the results.
